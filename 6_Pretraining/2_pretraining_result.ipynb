{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca81db4",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af88de",
   "metadata": {},
   "source": [
    "unfortunately, github wouldn't accept any upload with project size bigger than 2GB. <br/>\n",
    "so, I decided to add logs only <br/>\n",
    "(checkout `pretrain_checkpoint_log_only` for detailed logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0996c5",
   "metadata": {},
   "source": [
    "<img src=\"./loss_curve_u0025000.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d32ae",
   "metadata": {},
   "source": [
    "ok. that's freaking FABULOUS, HEALTHY, NICE LOOKING GRAPH. <br/> <br/>\n",
    "we got that classic steep early drop (the one around 0 - 1000?) <br/>\n",
    "then it smoothly decays over the rest until 25k iterations <br/>\n",
    "blue line and orange line aligns beautifully together; no overfitting there <br/>\n",
    "i do see some noise in around 10000th and 21000th iterations. but, i guess that's ok since it looks way better than the first version. <br/>\n",
    "the first version had pretty same trand as the one above, <br/>\n",
    "but blue graph was linearly decreasing with dramatic noise <br/>\n",
    "and orange graph was kind of tranding down as blue graph, but fluctuating so bad that majority of points were way above the blue graph (so, obviously overfitting there)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0cca69",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "yep. pretraining done. result looks really healthy <br/>\n",
    "so, yeah... we do have a model that technically ***knows how to speak*** but the result string would make no sense <br/>\n",
    "later on, that problem will be resolved by the time we perform Supervised Fine Tuning training (SFT)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
