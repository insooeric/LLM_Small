{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83715151",
   "metadata": {},
   "source": [
    "# SFT tweaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c175c4c",
   "metadata": {},
   "source": [
    "**!!!DISCLAIMER!!!**\n",
    "\n",
    "you may completely ignore this notebook <br/>\n",
    "i'm just jotting down the problems i've faced while modifying `train_sft.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8bff01",
   "metadata": {},
   "source": [
    "## Problems\n",
    "1. update speed is 180s/upd\n",
    "2. tps ≈500 \n",
    "3. on resume, foward ≈300, backward ≈6000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cce2c5",
   "metadata": {},
   "source": [
    "## idea\n",
    "1. foward ≈300 is fine. but, backward is too slow. make this 400 ~ 800\n",
    "2. increase tps ≈3000\n",
    "\n",
    "#### conclusion\n",
    "if we can decrease backward speed to around 400 ~ 800 and tps ≈3000, i'm pretty sure update speed would increase <br/>\n",
    "ok. let's see if we can reach around 20s/upd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba11cd4",
   "metadata": {},
   "source": [
    "# Solving backward speed ≈6000 problem\n",
    "## Problem found!\n",
    "yup. for some reason, SDPBackend.MATH was slowing down. <br/>\n",
    "so, i completely disabled using SDPBackend.MATH, but forced to use either FLASH_ATTENTION or EFFICIENT_ATTENTION <br/>\n",
    "\n",
    "- using fp16 + SDPBackend.FLASH_ATTENTION\n",
    "    - result: backward ≈3000\n",
    "- using bf16 + SDPBackend.EFFICIENT_ATTENTION\n",
    "    - result: backward ≈2000\n",
    "\n",
    "ok. stick with bf16 + SDPBackend.EFFICIENT_ATTENTION\n",
    "\n",
    "## Conclusion\n",
    "original was using fp16 + SDPBackend.MATH <br/>\n",
    "now, it uses bf16 + SDPBackend.EFFICIENT_ATTENTION <br/>\n",
    "(still can use fp16 + SDPBackend.FLASH_ATTENTION but i'm using the one above since it's faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d905a809",
   "metadata": {},
   "source": [
    "# ENV var conflicts forcing bad kernels\n",
    "## Problem\n",
    "`SDPA_BACKEND`, `PYTORCH_SDP_KERNEL` and shell overrides nudged PyTorch into slow paths\n",
    "## Solution\n",
    "cleared env overrides in script and used: <br/>\n",
    "- cuda_backend.enable_flash_sdp(False)\n",
    "- cuda_backend.enable_mem_efficient_sdp(True)\n",
    "- cuda_backend.enable_math_sdp(True)\n",
    "## Result\n",
    "yup. no longer seeing that kernel error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e263a4",
   "metadata": {},
   "source": [
    "# No FlashAttention in the wheel\n",
    "### Problem\n",
    "flash was unusable. torch was not compiled with flash attention\n",
    "### Solution\n",
    "i've upgraded from cu121 to cu124, set prefer mem-efficient SDPA; only Flash if actually available\n",
    "-> YES! now it's using bf16 + SDPBackend.EFFICIENT_ATTENTION\n",
    "### Result\n",
    "bf16 + SDPBackend.EFFICIENT_ATTENTION is working with no error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714baabb",
   "metadata": {},
   "source": [
    "# AMP/scaler mismatches\n",
    "### Problem\n",
    "calling GradScaler logic when using bf16 caused awkward code overheads\n",
    "### Solution\n",
    "guard everything with scaler and scaler.is_enabled()\n",
    "### Another Problem\n",
    "when using fp16, the graph was drastically fluctuating...\n",
    "### Solution for Another Problem\n",
    "use scaler only for fp16\n",
    "### Result\n",
    "now, both fp16 and bf16 are working fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14645a3e",
   "metadata": {},
   "source": [
    "# Stressed kernel\n",
    "### Problem \n",
    "backward time is showing 5k\n",
    "### Solution\n",
    "welp. i played around with `--micro-bsz` and `--accum` <br/>\n",
    "setting `--micro-bsz 8 --accum 8` did solve the problem\n",
    "### result\n",
    "yeah... the speed went lower to 2k with bf16 (but that's still slow...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e09f07f",
   "metadata": {},
   "source": [
    "# State dict shape/name mismatches\n",
    "### Problem\n",
    "checkpoint with split `q/k/v` vs fused qkv; PEFT `.base_layer` naming\n",
    "### Solution\n",
    "auto-fuse `q,k,v -> qkv` on load and map to `.base_layer` keys for LoRA\n",
    "### Result\n",
    "now, i no longer see that missing keys stuffs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8bdab",
   "metadata": {},
   "source": [
    "# Resume/scheduler drift\n",
    "### Problem\n",
    "LR scheduler wasn't alighed when resuming midrun\n",
    "### Solution\n",
    "fast--forward / rebuild scheduler to match remaining steps and current LR\n",
    "### Result\n",
    "on resume, now i do see stable initial values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2bc3a",
   "metadata": {},
   "source": [
    "# INFO\n",
    "currently, i see <br/>\n",
    "- `[profile] forward ≈200ms  backward ≈450ms  (no optimizer.step)`\n",
    "- `tps ≈4000` \n",
    "\n",
    "not THAT(?) bad but would be better if we can make it even faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692470d",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "let's try `--torch-compile`, `--compile-mode`\n",
    "### Result\n",
    "i tried both \n",
    "- `--compile-mode over-head`\n",
    "- `--compile-mode default`\n",
    "- `--compile-mode max-autotune`\n",
    "\n",
    "but they all dramatically increased backward speed (the highest one was ≈11000ms)<br/>\n",
    "yeah... better not use it..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725a5a1",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "let's try adding `--workers`\n",
    "### Result\n",
    "even 1 worker slow downs the update speed... (80s/upd) <br/>\n",
    "i'm just gonna use no workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeace180",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "let's try enabling TF32 for extra throughput <br/>\n",
    "additionally set `is_causal=True`\n",
    "\n",
    "# Result\n",
    "oh hey! <br/>\n",
    "i did `torch.backends.cuda.matmul.allow_tf32 = True` <br/>\n",
    "and `torch.set_float32_matmul_precision(\"high\")` <br/>\n",
    "\n",
    "it did increase the tps (tps ≈5500)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
